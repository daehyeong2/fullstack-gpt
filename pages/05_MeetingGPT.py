import streamlit as st
import subprocess
import math
from pydub import AudioSegment
import openai
import glob
import os

st.set_page_config(
    page_title="MeetingGPT",
    page_icon="ğŸ¤",
)

st.title("MeetingGPT")
st.markdown(
    "MeetingGPTì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ë©´ ëŒ€í™”ì˜ ìš”ì•½ê³¼ ëŒ€í™”ì— ëŒ€í•œ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆëŠ” ì±—ë´‡ì„ ì œê³µí•´ ë“œë¦½ë‹ˆë‹¤."
)


@st.cache_data()
def extract_audio_from_video(video_path):
    audio_path = (
        video_path.replace(".mp4", ".mp3")
        .replace(".avi", ".mp3")
        .replace(".mkv", ".mp3")
        .replace(".mov", ".mp3")
    )
    if os.path.exists(audio_path):
        return
    command = ["ffmpeg", "-y", "-i", video_path, "-vn", audio_path]
    subprocess.run(command)


@st.cache_data()
def cut_audio_in_chunks(audio_path, chunk_size, chunks_folder):
    if os.path.exists("./.cache/chunks/0_chunk.mp3"):
        return
    chunk_len = chunk_size * 60 * 1000
    track = AudioSegment.from_mp3(audio_path)
    chunks = math.ceil(len(track) / chunk_len)
    for i in range(chunks):
        start_time = i * chunk_len
        end_time = (i + 1) * chunk_len
        chunk = track[start_time:end_time]
        chunk.export(
            f"{chunks_folder}/{str(i).zfill(2)}_chunk.mp3",
            format="mp3",
        )


@st.cache_data()
def transcribe_chunks(chunk_folder, destination):
    if os.path.exists(destination):
        return
    files = glob.glob(f"{chunk_folder}/*.mp3")
    for file in files:
        with open(file, "rb") as audio_file, open(destination, "a") as text_file:
            transcript = openai.Audio.transcribe(
                "whisper-1",
                audio_file,
            )
            text_file.write(transcript["text"])


with st.sidebar:
    video = st.file_uploader(
        "Video",
        type=["mp4", "avi", "mkv", "mov"],
    )

if video:
    chunks_folder = "./.cache/chunks"
    with st.status("ì˜ìƒ ì²˜ë¦¬ ì¤‘..", expanded=True):
        st.write("ì˜ìƒ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..")
        video_content = video.read()
        video_path = f"./.cache/meeting_files/{video.name}"
        audio_path = (
            video_path.replace(".mp4", ".mp3")
            .replace(".avi", ".mp3")
            .replace(".mkv", ".mp3")
            .replace(".mov", ".mp3")
        )
        transcript_path = (
            video_path.replace(".mp4", ".txt")
            .replace(".avi", ".txt")
            .replace(".mkv", ".txt")
            .replace(".mov", ".txt")
        )
        with open(video_path, "wb") as f:
            f.write(video_content)
        st.write("ì†Œë¦¬ ì¶”ì¶œ ì¤‘..")
        extract_audio_from_video(video_path)
        st.write("ì†Œë¦¬ ë¶„í•  ì¤‘..")
        cut_audio_in_chunks(audio_path, 10, chunks_folder)
        st.write("ëŒ€ë³¸ ì¶”ì¶œ ì¤‘..")
        transcribe_chunks(
            chunks_folder,
            transcript_path,
        )

    transcript_tab, summary_tab, chat_tab = st.tabs(["ëŒ€ë³¸", "ìš”ì•½", "ëŒ€í™”"])

    with transcript_tab:
        with open(transcript_path, "r") as f:
            st.write(f.read())
