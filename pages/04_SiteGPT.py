from langchain.document_loaders import SitemapLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings
from langchain.storage import LocalFileStore
from langchain.schema.runnable import RunnablePassthrough, RunnableLambda
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from bs4 import BeautifulSoup
import streamlit as st

llm = ChatOpenAI(
    temperature=0.1,
)

answers_prompt = ChatPromptTemplate.from_template(
    """
ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¬¸ì„œë“¤ì„ ë³´ê³  ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ” ë¶€ë¶„ì„ ì°¾ì•„ ë‹µí•˜ê³  ë‹µë³€ì— ëŒ€í•œ ì ìˆ˜ë¥¼ ë¶€ì—¬í•´ì•¼ í•©ë‹ˆë‹¤.
ì ìˆ˜ëŠ” 0ì ë¶€í„° 5ì ê¹Œì§€ ìˆìœ¼ë©° 0ì ì€ ì“¸ëª¨ ì—†ëŠ” ë‹µë³€, 5ì ì€ ë§¤ìš° ìœ ìš©í•œ ë‹µë³€ì…ë‹ˆë‹¤.

ì˜ˆì‹œ:

ì§ˆë¬¸: ë‹¬ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ìˆë‚˜ìš”?
ë‹µ: ë‹¬ì€ 384,400 km ë§Œí¼ ë–¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.
ì ìˆ˜: 5

ì§ˆë¬¸: ë‹¬ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ìˆë‚˜ìš”?
ë‹µ: ë‹¬ì€ 384,400 ëª…ì…ë‹ˆë‹¤.
ì ìˆ˜: 0

ì§ˆë¬¸: íƒœì–‘ì€ ì–¼ë§ˆë‚˜ ë©€ë¦¬ ìˆë‚˜ìš”?
ë‹µ: ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.
ìŠ¤ì½”ì–´: 0

ë‹¹ì‹ ì˜ ì°¨ë¡€ì…ë‹ˆë‹¤!

ë¬¸ì„œ: {context}

ì§ˆë¬¸: {question}
""",
)

choose_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
    ì£¼ì–´ì§„ ë‹µë³€ë“¤ë§Œ ì´ìš©í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
     
    ì ìˆ˜ê°€ ë†’ì€ ë‹µë³€ë“¤ì„ ë” ì´ìš©í•˜ì„¸ìš”. (ë”ìš± ìœ ìš©í•œ ì •ë³´ì…ë‹ˆë‹¤)
    ê·¸ë¦¬ê³  ìµœê·¼ ì •ë³´ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ì´ìš©í•˜ì„¸ìš”.
    ì ìˆ˜ê°€ ë‚®ì€ ë‹µë³€ì€ ê²°ê³¼ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ”ë° ì‚¬ìš©ëœ ë‹µë³€ì˜ ì¶œì²˜ë“¤ì„ ë³€ê²½í•˜ì§€ ë§ê³ , ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
    ì¶œì²˜ëŠ” ë¬´ì¡°ê±´ í‘œì‹œí•´ì•¼ í•˜ë©° ë‚ ì§œëŠ” í‘œì‹œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.

    ë‹µë³€ë“¤: {answers}

    ì˜ˆì‹œ:

    ì§ˆë¬¸: Next.js ê°•ì˜ëŠ” ì–¼ë§ˆì´ë©° ìˆ˜ê°•ìƒì€ ëª‡ëª…ì¸ê°€ìš”?

    --------------ê²°ê³¼--------------
    Next.jsëŠ” 160,000ì›ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ í˜„ì¬ëŠ” í• ì¸ ì¤‘ì´ë¼ì„œ 75,000ì›ì…ë‹ˆë‹¤. ìˆ˜ê°•ìƒì€ 3866ëª…ì…ë‹ˆë‹¤.

    ì¶œì²˜: https://discord.com/about 
    --------------------------------
""",
        ),
        ("human", "{question}"),
    ]
)


def get_answers(inputs):
    docs = inputs["docs"]
    question = inputs["question"]
    answers_chain = answers_prompt | llm
    return {
        "question": question,
        "answers": [
            {
                "answer": answers_chain.invoke(
                    {"context": doc.page_content, "question": question}
                ).content,
                "source": doc.metadata["source"],
                "date": doc.metadata["lastmod"],
            }
            for doc in docs
        ],
    }


def choose_answer(inputs):
    answers = inputs["answers"]
    question = inputs["question"]
    choose_chain = choose_prompt | llm
    condensed = "\n\n".join(
        f"{answer['answer']}\nì¶œì²˜: {answer['source']}\në‚ ì§œ: {answer['date']}"
        for answer in answers
    )
    return choose_chain.invoke(
        {
            "question": question,
            "answers": condensed,
        }
    )


def parse_page(soup: BeautifulSoup):
    header = soup.find("header")
    footer = soup.find("footer")
    if header:
        header.decompose()
    if footer:
        footer.decompose()
    return str(soup.get_text()).replace("\n", " ").replace("\xa0", " ")


@st.cache_data(show_spinner="ì„ë² ë”© ì¤‘..")
def embed_file(url, _docs):
    cache_dir = LocalFileStore(f"./.cache/site_embeddings/{url.replace('/', '')}")
    embeddings = OpenAIEmbeddings()
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)
    vector_store = FAISS.from_documents(_docs, cached_embeddings)
    retriever = vector_store.as_retriever()
    return retriever


@st.cache_data(show_spinner="ì›¹ ì‚¬ì´íŠ¸ ì •ë³´ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..")
def load_website(url):
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000,
        chunk_overlap=200,
    )
    loader = SitemapLoader(
        url,
        parsing_function=parse_page,
    )
    loader.requests_per_second = 1
    docs = loader.load_and_split(text_splitter=splitter)
    retriever = embed_file(url, docs)
    return retriever


st.set_page_config(page_title="SiteGPT", page_icon="ğŸ–¥ï¸")

st.title("SiteGPT")


st.markdown(
    """
            ì›¹ ì‚¬ì´íŠ¸ì˜ ë‚´ìš©ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ì§ˆë¬¸í•´ ë³´ì„¸ìš”.

            ì‚¬ì´ë“œ ë°”ì—ì„œ ì›¹ ì‚¬ì´íŠ¸ì˜ URLì„ ì…ë ¥í•´ì„œ ì‹œì‘í•˜ì„¸ìš”.
"""
)

with st.sidebar:
    url = st.text_input(
        "URLì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
        placeholder="https://example.com",
    )


if url and ".xml" not in url:
    with st.sidebar:
        st.error("ì‚¬ì´íŠ¸ë§µ URLì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
elif url:
    retriever = load_website(url)
    query = st.text_input("ì›¹ ì‚¬ì´íŠ¸ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")
    if query:
        chain = (
            {"docs": retriever, "question": RunnablePassthrough()}
            | RunnableLambda(get_answers)
            | RunnableLambda(choose_answer)
        )
        result = chain.invoke(query)
        st.markdown(result.content)
